{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "157d76e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import MBartForConditionalGeneration, MBart50TokenizerFast\n",
    "import sacrebleu\n",
    "import sys\n",
    "import os\n",
    "sys.path.append(\"/fs/clip-scratch/sweagraw/contrastive-controlled-mt/IWSLT2022\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7b552db8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_file(fname):\n",
    "    data = []\n",
    "    with open(fname) as f:\n",
    "        for line in f:\n",
    "            data.append(line.strip())\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f0f6c8bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_data(tgt_lang, domain, split):\n",
    "    source = read_file(f\"../internal_split/en-{tgt_lang}/{split}.{domain}.en\")\n",
    "    formal_translations = read_file(f\"../internal_split/en-{tgt_lang}/{split}.{domain}.formal.{tgt_lang}\")\n",
    "    informal_translations = read_file(f\"../internal_split/en-{tgt_lang}/{split}.{domain}.informal.{tgt_lang}\")\n",
    "    return source, formal_translations, informal_translations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d70fa4a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "tgt_lang_to_code = {\n",
    "    \"hi\" : \"hi_IN\",\n",
    "    \"de\" : \"de_DE\",\n",
    "    \"es\" : \"es_XX\",\n",
    "    \"it\" : \"it_IT\",\n",
    "    \"ru\" : \"ru_RU\",\n",
    "    \"ja\" : \"ja_XX\"\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e254f74b",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = MBartForConditionalGeneration.from_pretrained(\"facebook/mbart-large-50-one-to-many-mmt\", cache_dir=\"/fs/clip-scratch/sweagraw/CACHE\")\n",
    "tokenizer = MBart50TokenizerFast.from_pretrained(\"facebook/mbart-large-50-one-to-many-mmt\", src_lang=\"en_XX\", cache_dir=\"/fs/clip-scratch/sweagraw/CACHE\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "47e08da5",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = MBartForConditionalGeneration.from_pretrained(\"../models/facebook/mbart-large-50-one-to-many-mmt-finetuned-en-to-xx-informal\", cache_dir=\"/fs/clip-scratch/sweagraw/CACHE\")\n",
    "tokenizer = MBart50TokenizerFast.from_pretrained(\"facebook/mbart-large-50-one-to-many-mmt\", src_lang=\"en_XX\", cache_dir=\"/fs/clip-scratch/sweagraw/CACHE\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "bb049864",
   "metadata": {},
   "outputs": [],
   "source": [
    "def translate_text(text, tgt_lang):\n",
    "    model_inputs = tokenizer(text, return_tensors=\"pt\", padding=True)\n",
    "\n",
    "    # translate from English to Hindi\n",
    "    generated_tokens = model.generate(\n",
    "        **model_inputs,\n",
    "        forced_bos_token_id=tokenizer.lang_code_to_id[tgt_lang_to_code[tgt_lang]]\n",
    "    )\n",
    "    return tokenizer.batch_decode(generated_tokens, skip_special_tokens=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "05146ce6",
   "metadata": {},
   "outputs": [],
   "source": [
    "src_lang = \"en\"\n",
    "tgt_lang = \"hi\"\n",
    "domain=\"combined\"\n",
    "split=\"dev\"\n",
    "source, formal_translations, informal_translations = get_data(tgt_lang, domain, split)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7937caed",
   "metadata": {},
   "outputs": [],
   "source": [
    "output_dir=f\"../experiments/{src_lang}-{tgt_lang}/mBART_informal/{domain}/\"\n",
    "os.makedirs(output_dir, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "29e699e9",
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "[enforce fail at CPUAllocator.cpp:68] . DefaultCPUAllocator: can't allocate memory: you tried to allocate 500108000 bytes. Error code 12 (Cannot allocate memory)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Input \u001b[0;32mIn [11]\u001b[0m, in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0m outputs \u001b[38;5;241m=\u001b[39m \u001b[43mtranslate_text\u001b[49m\u001b[43m(\u001b[49m\u001b[43msource\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtgt_lang\u001b[49m\u001b[43m)\u001b[49m\n",
      "Input \u001b[0;32mIn [8]\u001b[0m, in \u001b[0;36mtranslate_text\u001b[0;34m(text, tgt_lang)\u001b[0m\n\u001b[1;32m      2\u001b[0m model_inputs \u001b[38;5;241m=\u001b[39m tokenizer(text, return_tensors\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpt\u001b[39m\u001b[38;5;124m\"\u001b[39m, padding\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m      4\u001b[0m \u001b[38;5;66;03m# translate from English to Hindi\u001b[39;00m\n\u001b[0;32m----> 5\u001b[0m generated_tokens \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgenerate\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m      6\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mmodel_inputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      7\u001b[0m \u001b[43m    \u001b[49m\u001b[43mforced_bos_token_id\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtokenizer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlang_code_to_id\u001b[49m\u001b[43m[\u001b[49m\u001b[43mtgt_lang_to_code\u001b[49m\u001b[43m[\u001b[49m\u001b[43mtgt_lang\u001b[49m\u001b[43m]\u001b[49m\u001b[43m]\u001b[49m\n\u001b[1;32m      8\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      9\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m tokenizer\u001b[38;5;241m.\u001b[39mbatch_decode(generated_tokens, skip_special_tokens\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "File \u001b[0;32m/fs/clip-controllablemt/fenv/lib/python3.9/site-packages/torch/autograd/grad_mode.py:28\u001b[0m, in \u001b[0;36m_DecoratorContextManager.__call__.<locals>.decorate_context\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     25\u001b[0m \u001b[38;5;129m@functools\u001b[39m\u001b[38;5;241m.\u001b[39mwraps(func)\n\u001b[1;32m     26\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mdecorate_context\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m     27\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m():\n\u001b[0;32m---> 28\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/fs/clip-controllablemt/fenv/lib/python3.9/site-packages/transformers/generation_utils.py:1239\u001b[0m, in \u001b[0;36mGenerationMixin.generate\u001b[0;34m(self, inputs, max_length, min_length, do_sample, early_stopping, num_beams, temperature, top_k, top_p, repetition_penalty, bad_words_ids, bos_token_id, pad_token_id, eos_token_id, length_penalty, no_repeat_ngram_size, encoder_no_repeat_ngram_size, num_return_sequences, max_time, max_new_tokens, decoder_start_token_id, use_cache, num_beam_groups, diversity_penalty, prefix_allowed_tokens_fn, logits_processor, stopping_criteria, output_attentions, output_hidden_states, output_scores, return_dict_in_generate, forced_bos_token_id, forced_eos_token_id, remove_invalid_values, synced_gpus, **model_kwargs)\u001b[0m\n\u001b[1;32m   1234\u001b[0m     input_ids, model_kwargs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_expand_inputs_for_generation(\n\u001b[1;32m   1235\u001b[0m         input_ids, expand_size\u001b[38;5;241m=\u001b[39mnum_beams, is_encoder_decoder\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconfig\u001b[38;5;241m.\u001b[39mis_encoder_decoder, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mmodel_kwargs\n\u001b[1;32m   1236\u001b[0m     )\n\u001b[1;32m   1238\u001b[0m     \u001b[38;5;66;03m# 12. run beam search\u001b[39;00m\n\u001b[0;32m-> 1239\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbeam_search\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1240\u001b[0m \u001b[43m        \u001b[49m\u001b[43minput_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1241\u001b[0m \u001b[43m        \u001b[49m\u001b[43mbeam_scorer\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1242\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlogits_processor\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlogits_processor\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1243\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstopping_criteria\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstopping_criteria\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1244\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpad_token_id\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpad_token_id\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1245\u001b[0m \u001b[43m        \u001b[49m\u001b[43meos_token_id\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43meos_token_id\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1246\u001b[0m \u001b[43m        \u001b[49m\u001b[43moutput_scores\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_scores\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1247\u001b[0m \u001b[43m        \u001b[49m\u001b[43mreturn_dict_in_generate\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreturn_dict_in_generate\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1248\u001b[0m \u001b[43m        \u001b[49m\u001b[43msynced_gpus\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msynced_gpus\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1249\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mmodel_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1250\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1252\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m is_beam_sample_gen_mode:\n\u001b[1;32m   1253\u001b[0m     \u001b[38;5;66;03m# 10. prepare logits warper\u001b[39;00m\n\u001b[1;32m   1254\u001b[0m     logits_warper \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_logits_warper(\n\u001b[1;32m   1255\u001b[0m         top_k\u001b[38;5;241m=\u001b[39mtop_k, top_p\u001b[38;5;241m=\u001b[39mtop_p, temperature\u001b[38;5;241m=\u001b[39mtemperature, num_beams\u001b[38;5;241m=\u001b[39mnum_beams\n\u001b[1;32m   1256\u001b[0m     )\n",
      "File \u001b[0;32m/fs/clip-controllablemt/fenv/lib/python3.9/site-packages/transformers/generation_utils.py:1979\u001b[0m, in \u001b[0;36mGenerationMixin.beam_search\u001b[0;34m(self, input_ids, beam_scorer, logits_processor, stopping_criteria, max_length, pad_token_id, eos_token_id, output_attentions, output_hidden_states, output_scores, return_dict_in_generate, synced_gpus, **model_kwargs)\u001b[0m\n\u001b[1;32m   1975\u001b[0m         \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[1;32m   1977\u001b[0m model_inputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mprepare_inputs_for_generation(input_ids, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mmodel_kwargs)\n\u001b[0;32m-> 1979\u001b[0m outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1980\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mmodel_inputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1981\u001b[0m \u001b[43m    \u001b[49m\u001b[43mreturn_dict\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m   1982\u001b[0m \u001b[43m    \u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_attentions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1983\u001b[0m \u001b[43m    \u001b[49m\u001b[43moutput_hidden_states\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_hidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1984\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1986\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m synced_gpus \u001b[38;5;129;01mand\u001b[39;00m this_peer_finished:\n\u001b[1;32m   1987\u001b[0m     cur_len \u001b[38;5;241m=\u001b[39m cur_len \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39m\n",
      "File \u001b[0;32m/fs/clip-controllablemt/fenv/lib/python3.9/site-packages/torch/nn/modules/module.py:1102\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1098\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1099\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1100\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1101\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1102\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1103\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1104\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[0;32m/fs/clip-controllablemt/fenv/lib/python3.9/site-packages/transformers/models/mbart/modeling_mbart.py:1337\u001b[0m, in \u001b[0;36mMBartForConditionalGeneration.forward\u001b[0;34m(self, input_ids, attention_mask, decoder_input_ids, decoder_attention_mask, head_mask, decoder_head_mask, cross_attn_head_mask, encoder_outputs, past_key_values, inputs_embeds, decoder_inputs_embeds, labels, use_cache, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[1;32m   1318\u001b[0m         decoder_input_ids \u001b[38;5;241m=\u001b[39m shift_tokens_right(labels, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconfig\u001b[38;5;241m.\u001b[39mpad_token_id)\n\u001b[1;32m   1320\u001b[0m outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel(\n\u001b[1;32m   1321\u001b[0m     input_ids,\n\u001b[1;32m   1322\u001b[0m     attention_mask\u001b[38;5;241m=\u001b[39mattention_mask,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1335\u001b[0m     return_dict\u001b[38;5;241m=\u001b[39mreturn_dict,\n\u001b[1;32m   1336\u001b[0m )\n\u001b[0;32m-> 1337\u001b[0m lm_logits \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlm_head\u001b[49m\u001b[43m(\u001b[49m\u001b[43moutputs\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfinal_logits_bias\u001b[49m\n\u001b[1;32m   1339\u001b[0m masked_lm_loss \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1340\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m labels \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[0;31mRuntimeError\u001b[0m: [enforce fail at CPUAllocator.cpp:68] . DefaultCPUAllocator: can't allocate memory: you tried to allocate 500108000 bytes. Error code 12 (Cannot allocate memory)"
     ]
    }
   ],
   "source": [
    "outputs = translate_text(source, tgt_lang)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07e74ce9",
   "metadata": {},
   "outputs": [],
   "source": [
    " with open(output_dir+\"/out.\"+split, \"w\") as f:\n",
    "        for out in outputs:\n",
    "            f.write(out + \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "c37c7022",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Other decodng strategies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "ff45c18a",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_inputs = tokenizer(source[0], return_tensors=\"pt\", padding=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "de219137",
   "metadata": {},
   "outputs": [],
   "source": [
    "# translate from English to Hindi\n",
    "generated_tokens = model.generate(\n",
    "    **model_inputs,\n",
    "    forced_bos_token_id=tokenizer.lang_code_to_id[tgt_lang_to_code[tgt_lang]],\n",
    "    max_length=50, \n",
    "    num_beams=5, \n",
    "    num_return_sequences=5, \n",
    "    early_stopping=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "1688e8ae",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[     2, 250010,  10399, 188051,  45389,    421,  24062,   6143,    471,\n",
       "          33572,   4050,    471,  86990,  18224,  45718,      5,   4239,  21568,\n",
       "            871, 139041,    871, 219046,    460,    871,  33171,    460,      5,\n",
       "          15273,   3849,      4,   4239,  32243,   1480,    460,      5, 109440,\n",
       "            460,   1682,   4239,    460,      5,      2],\n",
       "        [     2, 250010,  10399, 188051,  45389,    421,  24062,   6143,    471,\n",
       "          33572,   4050,    471,  86990,  18224,  28035,      5,   4239,  21568,\n",
       "            871, 139041,    871, 219046,    460,    871,   4239,    460,      5,\n",
       "          15273,   3849,      4,   4239,  32243,   1480,    460,      5, 109440,\n",
       "            460,   1682,   4239,    460,      5,      2],\n",
       "        [     2, 250010,  10399, 188051,  45389,    421,  24062,   6143,    471,\n",
       "          33572,   4050,    471,  86990,  18224,  45718,      5,   4239,  21568,\n",
       "            871, 139041,    871, 219046,    460,    871,   4239,    460,      5,\n",
       "          15273,   3849,      4,   4239,  32243,   1480,    460,      5, 109440,\n",
       "            460,   1682,   4239,    460,      5,      2],\n",
       "        [     2, 250010,  10399, 188051,  45389,    421,  24062,   6143,    471,\n",
       "          33572,   4050,    471,  86990,  18224,  28035,      5,   4239,  21568,\n",
       "            871, 139041,    871, 219046,    460,    871,   4239,    460,      5,\n",
       "          15273,   3849,      4,   4239,  32243,   1480,    460,      5,   4239,\n",
       "         109440,    460,      5,      2,      1,      1],\n",
       "        [     2, 250010,  10399, 188051,  45389,    421,  24062,   6143,    471,\n",
       "          33572,   4050,    471,  86990,  18224,  45718,      5,   4239,  21568,\n",
       "            871, 139041,    871, 219046,    460,    871,  33171,    460,      5,\n",
       "          15273,   3849,      4,   4239,  32243,   1480,    460,      5, 109440,\n",
       "            460,   4239,    460,      5,      2,      1]])"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "generated_tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "c5343bf1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['मैं निकट भविष्य में आपके देश की यात्रा करने की आशा करता हूं. यह पूर्ण और सरल और मधुर है और यही है. ओह, यह कहता है. उम्मीद है कि यह है.',\n",
       " 'मैं निकट भविष्य में आपके देश की यात्रा करने की आशा करता हूँ. यह पूर्ण और सरल और मधुर है और यह है. ओह, यह कहता है. उम्मीद है कि यह है.',\n",
       " 'मैं निकट भविष्य में आपके देश की यात्रा करने की आशा करता हूं. यह पूर्ण और सरल और मधुर है और यह है. ओह, यह कहता है. उम्मीद है कि यह है.',\n",
       " 'मैं निकट भविष्य में आपके देश की यात्रा करने की आशा करता हूँ. यह पूर्ण और सरल और मधुर है और यह है. ओह, यह कहता है. यह उम्मीद है.',\n",
       " 'मैं निकट भविष्य में आपके देश की यात्रा करने की आशा करता हूं. यह पूर्ण और सरल और मधुर है और यही है. ओह, यह कहता है. उम्मीद है यह है.']"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.batch_decode(generated_tokens, skip_special_tokens=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "842767d9",
   "metadata": {},
   "source": [
    "# Evaluation Covariates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "90f2168f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer\n",
    "import sacrebleu\n",
    "import sys\n",
    "import os\n",
    "from transformers import AutoModelForSeq2SeqLM, DataCollatorForSeq2Seq, Seq2SeqTrainingArguments, Seq2SeqTrainer, MBartForConditionalGeneration, MBart50TokenizerFast"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "81dd2072",
   "metadata": {},
   "outputs": [],
   "source": [
    "from mbart_covariate import CMBartForConditionalGeneration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0688f543",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = CMBartForConditionalGeneration.from_pretrained(\"../models/facebook/mbart-large-50-one-to-many-mmt-finetuned-covariate-en-to-xx\", cache_dir=\"/fs/clip-scratch/sweagraw/CACHE\")\n",
    "tokenizer = MBart50TokenizerFast.from_pretrained(\"facebook/mbart-large-50-one-to-many-mmt\", src_lang=\"en_XX\", cache_dir=\"/fs/clip-scratch/sweagraw/CACHE\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6b499b64",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "def translate_text(text, tgt_lang, covariate_index):\n",
    "    model_inputs = tokenizer(text, return_tensors=\"pt\", padding=True)\n",
    "    kwargs = {}\n",
    "    kwargs[\"covariate_ids\"] = torch.tensor([covariate_index]*len(text))\n",
    "\n",
    "    # translate from English to Hindi\n",
    "    generated_tokens = model.generate(\n",
    "        **model_inputs,\n",
    "        forced_bos_token_id=tokenizer.lang_code_to_id[tgt_lang_to_code[tgt_lang]],\n",
    "        **kwargs\n",
    "    )\n",
    "    return tokenizer.batch_decode(generated_tokens, skip_special_tokens=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "1ec8e585",
   "metadata": {},
   "outputs": [],
   "source": [
    "outputs = translate_text(source, tgt_lang, covariate_index=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "fc008c1b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['असल में डिज़्नी के सभी चीजों में मिकी माउस चित्रों को ढूँढ़ने के लिए एक छुपे उपकौशंसल मौजूद है, आपको जरूर देखना चाहिए!',\n",
       " 'हाँ, बहुत बढ़िया बात है। शायद तुम्हारे कुत्ते दानदाता हो सकते हैं। मुझे उम्मीद है कि ड्राइव पर कुत्तों को बहुत से चखाने मिलेंगे।',\n",
       " 'सही है, लेकिन मुझे लगता है कि बिल्लियाँ बहुत से राजनीतिज्ञों से ज़्यादा होशियार हैं। क्या आप देखते हैं कि आपका आम हाउस सदस्य लम्बे समय तक अलग रहता है?',\n",
       " 'यह गारंट नहीं है कि आप खेल जीतेंगे लेकिन यह सुनिश्चित करता है कि यह बहुत आसान हो जाएगा. लोल. एक बढ़िया दिन है.',\n",
       " 'हाँ यह समझ में आया है, क्या आपने सुना है कि उनके पास 10 मिलियन डॉलर का बांकर है?',\n",
       " 'हाँ, और ज़्यादातर जगहों पर आप अभी भी अपने खाते पर पहुँच कर सकते हैं क्योंकि यह चीन, सीरिया, उत्तर कोरिया और क्रिमा के अलावा देशों में उपलब्ध है।',\n",
       " 'मुझे पता है कि क्या आप अतिरिक्त प्रत्यय प्राप्त कर सकते हैं अगर आप उस कक्षा के लिए अपने बाल उगाने शुरू कर देते हैं? लोल मुझे कॉलेज में एक पौराणिक और कल्पना कक्षा थी। यह बहुत अच्छा था।',\n",
       " 'यह मेरा उपनाउँ था! इसलिए नहीं कि मैं शेक्सपियर की तरह बड़ा हूँ... क्योंकि वह पोकाहोंट्स के समय जीवित था, जो मैं से थोड़ा बड़ा है. शेक्सपियर पर आपका क्या विचार है?',\n",
       " 'लोल, मुझे पता है कि आपको यह मजा लेना होगा अगर आप कुछ नई कोशिश कर रहे हैं! पानी के साथ कुछ अलग करना दिलचस्प है। लेकिन, इसे एक बिल्लू की तरह लपेटना मजेदार नहीं लगता।',\n",
       " 'यह बहुत बढ़िया है। क्या आपने फ़िल्म ब्लाज़िंग सैडल्स देखी है?',\n",
       " 'हाँ, यह बहुत दिलचस्प है। क्या तुम गूनी को देखा?',\n",
       " 'मैंने पहले योग लिया है लेकिन इससे पहले मुझे कुछ और कक्षाएं चाहिएं ताकि मैं और लचीला हो जाऊं।',\n",
       " 'मैं संगीत और सौहार्द को पसंद करता हूँ। आपका पसंदीदा कलाकार कौन है?',\n",
       " 'क्या आज रात सूर्य आपके इंटरनेट संकेत को बंद कर रहा है?',\n",
       " 'मैं आपसे सहमत हूँ! खास तौर पर बॉक्स ऑफिस पर जो है। मुझे ट्रॉलियन वॉर्स के लिए काम करना पसंद नहीं था। उन्होंने 15 मिलियन की बजट पर सिर्फ 309 डॉलर कमाए!',\n",
       " 'हाँ, मुझे समझ में आया है! लोग वहाँ अपनी पहचान का खुदा करना चाहते हैं। जैज़ काफी बड़ा है। आप वहाँ अपने को कॉल करने के लिए कुछ मिल सकता है।',\n",
       " 'नहीं, मैंने नहीं कहा, लेकिन मैं पूरी तरह से आपके साथ सहमत हूँ। मुझे लगता है कि दुबई मरुस्थली में है इसलिए उन्हें घास को हरा रखने के लिए काफी पानी की आवश्यकता है, लेकिन अभी भी ऐसा लगता है कि उस पर खेलना गलत है।',\n",
       " 'वैसे, क्या आप क्रिस प्रैट के बारे में सोचते हैं? यह मजेदार है कि उन्होंने नई गार्डियंस ऑफ़ द गैलेक्सी फ़िल्म के लिए डिरेक्सर जेम्स ग्न को फिर से नियुक्त करना चाहा था',\n",
       " 'मैं पोकेमोन खेलना पसंद करता था, क्या आपने कभी खेला है या सीडी देखी है?',\n",
       " 'दिलचस्प है। ओरेगॉन में बहुत बरसात होती है, क्या तुमने कभी देखी है?',\n",
       " 'नहीं, मैंने वह सीडी नहीं देखी, तो तुम्हें पॉप संगीत पसंद है?',\n",
       " 'मुझे नहीं लगता कि मैंने उन्हें देखा है। मैं बहुत से ध्यान से अद्भुत श्रृंखला का अनुसरण नहीं करता। मुझे पता है कि क्रिस प्रैट टीवी, पार्क्स और रेकेक्ट पर एक शो में भूमिका निभाता है। क्या आपने इसे देखा है?',\n",
       " \"WOw मैं असल में कि कोशिश करना चाहता हूँ। यूनिसेफ़ स्वच्छ पानी donated when you don't use your hpone\",\n",
       " 'मैं सहमत हूँ, तो तुम्हें फ़िक्शन पसंद है?',\n",
       " 'क्या तुम्हें पसंदीदा फ़िल्में दिखाई देती हैं?',\n",
       " 'हाँ, बफ़्लो में बस मॉल जाना छोड़कर बहुत कुछ नहीं किया जा सकता! इसलिए, चूंकि आपने कैडीलाक नहीं पहना है, आपके जीवन में आपके पास क्या कारें हैं?',\n",
       " 'क्या आपने कभी खुद भी खेला है, नहीं, मैं अमरीका से नहीं आया हूँ।',\n",
       " 'मुझे इस क़िस्म से कोई परेशानी नहीं है, जब तक मुझे मजा आता है। तुम अपने फ़िल्में कैसे देखते हो, टीवी पर या कंप्यूटर पर?',\n",
       " 'एक जोखिम भी ले सकता है. लेब्रॉन इस साल अच्छे दिख रहा है. वह इतना ध्यान दिया गया है. तुम्हारी पसंदीदा खिलाड़ी?',\n",
       " 'हाँ, यह बढ़िया है। तुम्हें क्या लगता है विन डिज़ल एक गुप्त लिपि प्राप्त करने के बारे में जो कि ग्रूट वास्तव में फ़िल्मों में बात कर रहा है बताता है',\n",
       " 'कि दिलचस्प है मैं हमेशा सोचा है कि, क्या आप अपनी खोजों के लिए गूगल का इस्तेमाल करते हैं? या किसी और वेबसाइट?',\n",
       " 'आपका पसंदीदा बैटमैन फ़िल्म क्या है? मेरा द डार्क नाइट है. मुझे सुना है कि स्ल्यूलविल शुरू में ब्रूस वेन बैटमैन बनना था. मुझे लगता है कि वो हालांकि गोथम बन गया था.',\n",
       " 'मुझे भी अच्छा लगता है! मैंने कभी नहीं सुना है कि, यह बहुत बढ़िया होगा, क्या आप अपना कार या गाड़ी का इस्तेमाल करते हैं?',\n",
       " 'मुझे निश्चित रूप से देख सकता था। क्या आपके पसंदीदा वीडियो गेम थे? जेन मैगॉनगियाजी ने उस अध्ययन के पीछे गेम डिज़ाइनर था, बहुत बढ़िया।',\n",
       " 'हाँ, अच्छी बात करके बहुत अच्छा लगा।',\n",
       " 'हाँ, मैं बड़े होने के बाद बहुत Nintendo खेलता था। अपने बारे में क्या सोचते हो?',\n",
       " 'यहीं। आज का दिन अपना आदर्श दिन बनाने की कोशिश करो, चाहे वह कितना भी क्यों न हो।',\n",
       " 'कि इसे खाना देखना एक अद्भुत दृश्य होना चाहिए। अपने शत्रुओं से छुटकारा पाने का एक अच्छा तरीका! LOL',\n",
       " \"आपके नाम '' कैथोड रे ट्यूब मनोरंजन डिवाइस '' पर क्या राय हैं?\",\n",
       " 'दिलचस्प है। क्या आपने उस फ़िल्म देखी है? मैंने देखी है।',\n",
       " 'सहमत. क्या आप नवीनतम किस्त देखने की योजना बना रहे हैंः एम आई फ़ैलआउट?',\n",
       " 'मैं ऐसा करता हूँ, हर साल एक नई पोशाक पहनता हूँ, तुम्हें पता है पांडा के शोधकर्ता काम के लिए पांडा पोशाक पहनते हैं।',\n",
       " 'मुझे पता है जैसे उन्होंने बुबा गुंप् में काम किया था। आपसे बात करके अच्छा लगा!',\n",
       " 'हाय आईम बहुत बढ़िया काम कर रहे हैं? क्या आपको पढ़ना पसंद है?',\n",
       " 'हाँ। ऐसा लगता है कि युवा। आपसे बात करके अच्छा लगा!',\n",
       " 'मुझे वो पसंद थी ब्यूटी एंड द बीस्ट में. Netflix पर है अगर आपको पहुँच है. बचपन की याद वापस लाता है',\n",
       " 'मुझे यह पसंद है। यह देखने के लिए इतनी मज़ेदार तेज़ी वाले खेल है। क्या आपको यह पसंद है?',\n",
       " 'बहुत से लोग सोचते हैं कि सभी साइकिल साइकिल हैं, लेकिन मैंने पढ़ा है कि सभी साइकिल साइकिल नहीं हैं। क्या आपने साइकिल के बारे में फ़िल्में देखी हैं?',\n",
       " 'गुड मॉर्निंग! क्या आपने कभी के-पॉप के बारे में सुना है?',\n",
       " 'मैंने कुछ समय से डिज़्नी फ़िल्म नहीं देखी है। क्या आपके पास कोई सिफारिश है?',\n",
       " 'क्योंकि इन उत्तरों को हमेशा सही किया जा सकता है, लेकिन कभी-कभार वे सही नहीं होते हैं। तो यह एक और चुनौती है। लेकिन अपने शिक्षण में और अधिक कौशल प्राप्त करने का एक और अवसर भी है,',\n",
       " 'टिकट की वापसी के बारे में जानकारी प्राप्त करने के लिए कृपया अपना PIN नंबर, यात्री नाम रिकार्ड डालें और अपनी टिकट नंबर जोड़ें। हम यात्री को रद्द करने की अनुमति देते हैं।',\n",
       " 'वे मेरे बारे में बात कर रहे हैं, वे क्या बौछार कर रहे हैं? तो मैंने कहा क्या आप कर रहे हैं? हम आपके फ़ेसबूक से कुछ तस्वीर ले जा रहे हैं और हम तुम्हें एक डेटिंग साइट बनाने जा रहे हैं।',\n",
       " 'चालीस डॉलर या कुछ और अच्छे टीवी की तरह था और उन्होंने सचमुच दस बजे चौदहवीं सड़क पर भाग लिया, लेकिन आपको यह मिला।',\n",
       " 'आप देख सकते हैं, यह बहुत कुछ हो सकता है जहाँ आप घर आते हैं, आपके बच्चों की देखभाल की जाती है, जहाँ वे थे',\n",
       " 'मैं अपने बच्चों को सबसे पहले रखता हूँ, खासकर काम और दूसरी चीज़ों को रखने से पहले। तो, मेरे बच्चे हमेशा पहले आते हैं, काम से पहले, इसलिए यह हमेशा परिवार सबसे पहले होता है।',\n",
       " 'तो अपने बचपन के सबसे अच्छे दोस्त के बारे में बताओ।',\n",
       " 'क्योंकि मुझे लगता है, आपके परिवार की तरह नहीं, उनके मामले में हम में से कोई भी सच में रास्ता नहीं चलता।',\n",
       " 'क्या आपने अपने फ़्रीलेंसर के खाते में क्रेडिट कार्ड डालने के लिए क्रेडिट कार्ड रखा है?',\n",
       " 'तो तुम असल में जाओ, मैं अपने खाते बंद कर रहा हूँ',\n",
       " 'खैर, और तुम्हें पता है, मुझे क्या लगता है कि अगर पुरुष इसे करने के लिए एक प्रतिस्पर्द्धा है जैसा कि उन्होंने कहा मुझे अपनी नंबर मेरी बहन से प्राप्त करने के लिए,',\n",
       " 'लेकिन मुझे पता है कि आप उनके साथ अपने रिश्ते के बारे में क्या महसूस करते हैं। यह बस ऐसा ही है जैसे आपको रिश्ता है, आपको लगता है जैसे आपका रिश्ता',\n",
       " 'तुम्हेंं पता है कि आपकों किसी का ट्यूशन करने की ज़रूरत है, आपकों किसी से बात करने की ज़रूरत है।',\n",
       " 'नीली जून्स जाने का रास्ता था। पता चला है बहुत नहीं है। खुदरा शॉप पर आपकी क्या राय हैं',\n",
       " '(honestly take care of) मेरे बच्चे मेरे माता-पिता जानते हैं। तो वे मुझे कैसे पालते हैं। अगर तुम सबसे अच्छी बात के बारे में सोच सकते हैं, कैसे तुम अपने माता-पिता और चीज़ों द्वारा पाल लिया गया था।',\n",
       " 'मेरे पास काम है, मैं क्या कह रहा हूँ, मैं काम पहले रखता हूँ, मुझे काम करना है',\n",
       " 'हाँ ज़िंदगी में ले जा रहा हूँ तुम्हें पता है मैं क्या कह रहा हूँ',\n",
       " 'उन्होंने कभी भी हाथ नहीं बढ़ाया और कहा, अपना हाथ काटने पर तुम्हें कभी अफसोस नहीं होता।',\n",
       " 'तुम मुझे एक दोस्त देना',\n",
       " 'और अपने आपको व्यक्त करने का तरीका यह है जैसे, आपको पता है, जो उदाहरण आपने दिए हैं उनका मतलब है कि बहुत ज़्यादा नैतिकता है।',\n",
       " 'तुम्हें पता है जैसे किसी तरह से तुम्हें पता है कि वे इसे बैग में पैक करने और आकर्षित करने में सक्षम थे, वे सभी नई हैं और सिर्फ़ इसे वहाँ छोड़ दिया',\n",
       " 'फिर तुम्हारा दूसरा पसंदीदा कौन सा है',\n",
       " 'वे बहुत से कम उम्र के लोग हैं, उनकी शुरुआती बीस के दशक में, बीस के दशक के बीच, महिला जो इस जगह चला था बहुत अच्छा था, बहुत आरामदायक. वे अपने चुप्पी नहीं बुस्ट किया, तुम्हें पता है?',\n",
       " '(ठीक है, मुझे याद है) मेरे पास एक सवाल है तुम्हारे लिए है। क्या आपके पास कई, समझाने के लिए सबसे अच्छा तरीका यह है कि कैसे मेरे शहर काम करता है',\n",
       " 'यकीन है, क्या मैं आपके ZIP कोड और स्ट्रीट नाम भी ले सकता हूँ?',\n",
       " 'कोई भी आपकी पूछताछ केवल इस वेबसाइट के जरिए टिकट ख़रीदने से ही समर्थित हो सकती है। ठीक है, इसलिए हम नहीं ख़रीद चुके हैं, अगर आप किसी अन्य वेबसाइट के जरिए अपनी टिकट ख़रीदते हैं तो आपको टिकट की जाँच करनी होगी।',\n",
       " 'और तुम बस आमतौर पर Amazon को वापस?',\n",
       " 'आप लोगों और पीटर से भरे श्रोताओं की तरह अपने काम के जीवन के बारे में एक कहानी बताने जा रहे हैं',\n",
       " 'लेकिन उनकी कीमतें इतनी बढ़िया हैं, और फिर वे बहुत से चीज़ें हैं कि तुम बस की तरह की कोशिश कर रहे हैं',\n",
       " 'जैसे क्या? तुम्हारे हाथ के साथ क्या हुआ? मैं कुछ नहीं कहना चाहता था. मुझे पता भी नहीं था कि इसे कैसे कहना है और मैं कहूँगा कि मुझे काट गया था',\n",
       " 'ओह भगवान, मैं विल फ़रेल से नफरत करता हूँ. तो तुम्हारा पसंदीदा फ़िल्म क्या है? विल फ़रेल के साथ फ़िल्म. मैं प्याज से नफरत करता हूँ',\n",
       " 'तुम्हें पता है, यह लाइन बहुत लंबा हो सकता है लगता है।',\n",
       " 'ठीक है, तुम सभी साफ हो. अपने अपार्टमेंट में जाओ या उन्हें जाने दो. तो, तुम्हें पता है, कि हमेशा चलता है. देखो, मुझे नहीं पता है यह कितना लंबा हो रहा है',\n",
       " 'तुम बस, सिर्फ़ एक चीज़ है जो मरे जा रही है, अपनी सप्ताहांत और छुट्टियाँ और ऐसी सभी चीज़ें बुक की गई हैं।',\n",
       " 'तुम्हारी माँ तुम्हें बेकार उपहार भेजती है।',\n",
       " 'नहीं अपने भाई या अपने जैसे जिसे आप अपने चचेरे भाई समझते हैं',\n",
       " 'इसका मतलब है कि आपके कंप्यूटर पर किसी वजह से पर्याप्त जगह नहीं है।',\n",
       " 'जहाँ तुम्हें पता है कि धोने के लिए जाने पर आप खुद को साफ कर सकते हैं तेलों और गंधों और उन चीज़ों के बारे में, बेशक सब का गंध बढ़िया था, सिर्फ़ स्वच्छता थी और वो बढ़िया था।',\n",
       " 'हाँ वे बढ़िया हैं, तुम्हें पता है मैं क्या कह रहा हूँ?',\n",
       " 'कंप्यूटर पर एक ही तरह से हम इसे अपने दोस्तों के साथ जाँचते हैं, अपने बच्चों या अपने बैंड के साथ काम करते हैं, तो यह जीवन का एक तथ्य है कि बहुत से लोग समाचार इस तरह मिलता है।',\n",
       " 'अपने कार के पीछे बैठते हुए और सड़क पर ध्यान नहीं देना। साल में कितने घंटे तुम ड्राइविंग का इस्तेमाल करते हो और कैसे तुम उससे अधिक उत्पादक हो सकते हो।',\n",
       " 'इसलिए वे सभी सही हैं, वे थोड़ा पागल हैं, तुम्हें पता है मैं क्या कह रहा हूँ?',\n",
       " 'मुझे नहीं पता। क्या मैं बस सच में बहुत बड़ा हूँ और संपर्क से बाहर है लेकिन, मुझे अजीब लगता है।',\n",
       " 'हाँ। मैं तैयार हूँ, तो शायद इसलिए मैं उस शो को देख रहा हूँ। मुझे नहीं पता, लेकिन मैं उस शो को देख रहा हूँ जो हो सकता है। तुम्हारा क्या है?',\n",
       " 'आप जानते हैं मैं क्या कह रहा हूँ मेरा परिवार राज्य से बाहर है',\n",
       " 'वैसे भी डाएट आपकी सबसे बड़ी समस्या है।',\n",
       " 'जब हम छोटे थे, आपका फ़ोन केस और आपका क्लिप, वो एक फ़ैशन सहायक था, और यह सच में अब नहीं है। आपका फ़ोन सिर्फ आपका फ़ोन है। लोग एक तरह से उस से आगे बढ़ गए हैं।',\n",
       " 'लेकिन उन्होंने किया और हम जा रहे थे और यह एक बहुत बढ़िया अनुभव था। मैं नहीं कहूँगा कि यह सिर्फ़ इतनी सकारात्मक और जादूगर था क्योंकि यह ऐसा लगता था',\n",
       " 'मदद आगे क्या आप चाहते हैं वे सिर्फ बातचीत कौशल हैं जो हर हालात में हर किसी के साथ इस्तेमाल किया जा सकता है।',\n",
       " 'परिवार तुम्हें बहुत से छोटे तरीके से मदद करता है कि तुम भी सोचते नहीं हैं। तुम्हें आजादी मिल गया']"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "e7d4db11",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['असल में डिज़्नी के सभी चीजों में मिकी माउस चित्रों को ढूँढ़ने के लिए एक छुपे उपसंस्कृति है, आपको जरूर देखना चाहिए!',\n",
       " 'हाँ, बहुत बढ़िया बात है। शायद आपके कुत्ते दानदाता हो सकते हैं। मुझे उम्मीद है कि ड्राइव पर कुत्तों को बहुत से चखाने मिलेंगे।',\n",
       " 'सच है, लेकिन मुझे लगता है कि बिल्लियाँ बहुत से राजनीतिज्ञों की तुलना में ज़्यादा होशियार हैं। क्या आप देखते हैं कि आपका आम सदस्य लम्बे समय तक विभाजन करता है?',\n",
       " 'यह आपको इस खेल को जीने की गारंटी नहीं देगी लेकिन इससे इसे बहुत आसान हो जाएगा. लोल. एक बढ़िया दिन बिताओ.',\n",
       " 'हाँ यह समझ में आया है, क्या आपने सुना है कि उनके पास 10 मिलियन डॉलर का बंकर है?',\n",
       " 'हाँ, और बहुत से स्थानों पर आप अभी भी अपने खाते पर पहुँच कर सकते हैं क्योंकि यह चीन, सीरिया, उत्तर कोरिया और क्रिमा के अलावा देशों में उपलब्ध है।',\n",
       " 'मुझे पता है कि क्या आप अतिरिक्त प्रत्यय प्राप्त कर सकते हैं अगर आप उस कक्षा के लिए अपने बाल उगाने शुरू कर देते हैं? लोल मुझे कॉलेज में एक पौराणिक और कल्पना कक्षा थी। यह बहुत अच्छा था।',\n",
       " 'यह मेरा उपनाम था! इसलिए नहीं कि मैं शेक्सपियर की तरह बड़ा हूँ... क्योंकि वह पोकाहोंटस के समय जीवित था, जो मुझे थोड़ा बड़ा है. शेक्सपियर पर आपका क्या विचार है?',\n",
       " 'लोल, मुझे पता है कि आपको यह मजा लेना होगा अगर आप कुछ नई कोशिश करें! पानी के साथ कुछ अलग करना दिलचस्प है। लेकिन, इसे एक बिल्लू की तरह लपेटना मज़ाक नहीं लगता है।',\n",
       " 'यह बहुत बढ़िया है। क्या आपने फ़िल्म ब्लाज़िंग सैडल्स देखी है?',\n",
       " 'हाँ, यह बहुत दिलचस्प है। क्या तुम गुनीज़ को देखा?',\n",
       " 'मैंने पहले योग लिया है लेकिन इससे पहले मुझे कुछ और कक्षाएं चाहिएं ताकि मैं और लचीला हो जाऊँ। आपसे बात करके मजा आया, अच्छा दिन बिताओ!',\n",
       " 'मुझे मैलोडी और हार्मोनिया पसंद है। आपका पसंदीदा कलाकार कौन है?',\n",
       " 'क्या सूर्य तुम्हारी इंटरनेट सिग्नल को आज रात बंद कर रहा है?',\n",
       " 'मैं आपसे सहमत हूँ! खासकर बॉक्स ऑफिस पर जो है। मुझे ट्रूजन वॉर्स के लिए काम करना पसंद नहीं होगा। वे सिर्फ़ 309 डॉलर कमा गए 15 मिलियन की बजट पर!',\n",
       " 'हाँ, मुझे समझ में आया है! लोग वहाँ अपनी पहचान का खुदा करना चाहते हैं। जैज़ बहुत बड़ा है। आप वहाँ अपने खुद को कॉल करने के लिए कुछ मिल सकता है।',\n",
       " 'नहीं, लेकिन मैं पूरी तरह से आपके साथ सहमत हूँ। मुझे लगता है कि दुबई मरुस्थली में है इसलिए उन्हें घास को हरित रखने के लिए काफी पानी की आवश्यकता है लेकिन अभी भी ऐसा लगता है कि उस पर खेलना ग़लत है।',\n",
       " 'वैसे, आप क्रिस प्रैट के बारे में क्या सोचते हैं? यह मजेदार है कि उन्होंने नई गार्डियंस ऑफ़ द गैलेक्सी फ़िल्म के लिए डिरेक्सर जेम्स ग्न को फिर से नियुक्त करना चाहा था',\n",
       " 'मैं पोकेमोन खेलना पसंद करता था, क्या आपने कभी खेला है या सीडी देखी है?',\n",
       " 'दिलचस्प है। ओरेगॉन में बहुत बरसात होती है, क्या आपने कभी देखी है?',\n",
       " 'नहीं, मैंने वह सीडी नहीं देखी, तो तुम्हें पॉप संगीत पसंद है?',\n",
       " 'मुझे नहीं लगता कि मैंने उन को देखा है। मैं बहुत से निशानी श्रृंखला का अनुसरण नहीं करता। मुझे पता है कि क्रिस प्रैट टीवी, पार्क्स और रेकेक्ट पर एक शो में भूमिका निभाता है। क्या आपने इसे देखा है?',\n",
       " \"WOw मैं असल में कि कोशिश करना चाहता हूँ। यूनिसेफ़ स्वच्छ पानी donated when you don't use your hpone\",\n",
       " 'मैं सहमत हूँ, तो क्या आपको फ़िक्शन पसंद है?',\n",
       " 'क्या तुम्हें पसंदीदा फ़िल्में दिखाई देती हैं?',\n",
       " 'हाँ, बफ़्लो में बस मॉल जाना छोड़कर बहुत कुछ नहीं किया जा सकता! इसलिए, चूंकि आपने कैडीलाक नहीं पहना है, आपके जीवन में आपके पास कौन सी कारें हैं?',\n",
       " 'क्या आपने कभी खुद भी खेला है, नहीं, मैं अमरीका से नहीं आया हूँ।',\n",
       " 'मुझे इस क़िस्म से कोई परेशानी नहीं है, जब तक मुझे मजा आता है। आप अपने फ़िल्में कैसे देखते हैं, टीवी पर या कंप्यूटर पर?',\n",
       " 'एक जोखिम भी ले सकता है. लेब्रॉन इस साल अच्छे दिख रहा है. वह इतना ध्यान दिया गया है. तुम्हारी पसंदीदा खिलाड़ी?',\n",
       " 'हाँ, यह बढ़िया है। ओल। आपको क्या लगता है विन डिज़ल एक गुप्त लिपि प्राप्त करने के बारे में जो कि ग्रूट वास्तव में फ़िल्मों में क्या बात कर रहा है बताता है',\n",
       " 'कि दिलचस्प है मैं हमेशा सोचा है कि, क्या आप अपनी खोजों के लिए गूगल का इस्तेमाल करते हैं? या किसी और वेबसाइट?',\n",
       " 'आपका पसंदीदा बैटमैन फ़िल्म क्या है? मेरा द डार्क नाइट है. मुझे सुना है कि स्ल्यूलविल शुरू में ब्रूस वेन बैटमैन बनना था. मुझे लगता है कि हालांकि गोथम बन गया था.',\n",
       " 'मुझे भी अच्छा! मैंने कभी नहीं सुना है कि, यह बहुत बढ़िया होगा, क्या आप अपना कार या गाड़ी का इस्तेमाल करते हैं?',\n",
       " 'मुझे निश्चित रूप से देख सकता था। क्या आपके पसंदीदा वीडियो गेम थे? जेन मैगॉनगियाजी ने उस अध्ययन के पीछे गेम डिज़ाइनर था, बहुत बढ़िया।',\n",
       " 'हाँ, अच्छी बात करके बहुत अच्छा लगा।',\n",
       " 'हाँ, मैं बड़े होने के बाद बहुत Nintendo खेलता था। अपने बारे में क्या सोचते हो?',\n",
       " 'यहीं। आज का दिन अपना आदर्श दिन बनाने की कोशिश करो, चाहे वह कितना भी क्यों न हो।',\n",
       " 'कि इसे खाना देखने के लिए एक अद्भुत दृश्य होना चाहिए। अपने शत्रुओं से छुटकारा पाने के लिए एक अच्छा तरीका! LOL',\n",
       " \"आपके नाम '' कैथोड रे ट्यूब मनोरंजन डिवाइज़ '' पर क्या राय हैं?\",\n",
       " 'दिलचस्प। क्या आपने उस फ़िल्म देखी है? मैंने देखी है।',\n",
       " 'सहमत. क्या आप नवीनतम किस्त देखने की योजना बना रहे हैंः एम आई फ़ैलआउट?',\n",
       " 'मैं ऐसा करता हूँ, हर साल एक नई पोशाक पहनता हूँ, आपको पता है पांडा के शोधकर्ता काम के लिए पांडा पोशाक पहनते हैं।',\n",
       " 'मुझे पता है जैसे उन्होंने बुबा गुंप् में काम किया था। आपसे बात करके अच्छा लगा!',\n",
       " 'हाय आईम बहुत बढ़िया काम कर रहे हैं? क्या आपको पढ़ना पसंद है?',\n",
       " 'हाँ। ऐसा लगता है कि युवा। आपसे बात करके अच्छा लगा!',\n",
       " 'मुझे वो पसंद थी ब्यूटी एंड द बीस्ट में. इसे नेटफ़िक्स पर है अगर आपको पहुँच है. बचपन की याद वापस लाता है',\n",
       " 'मुझे यह पसंद है। यह देखने के लिए इतनी मज़ेदार तेज़ी वाले खेल है। क्या आपको यह पसंद है?',\n",
       " 'बहुत से लोग सोचते हैं कि सभी शैकर मारने वाले शैकर हैं, लेकिन मैंने पढ़ा है कि सभी शैकर मारने वाले शैकर नहीं हैं। क्या आपने शैकर के बारे में फ़िल्में देखी हैं?',\n",
       " 'गुड मॉर्निंग! क्या आपने कभी के-पॉप के बारे में सुना है?',\n",
       " 'मैंने कुछ समय से डिज़्नी फ़िल्म नहीं देखी है। क्या आपके पास कोई सिफारिश है?',\n",
       " 'क्योंकि इन जवाबों को हमेशा सही किया जा सकता है, लेकिन कभी-कभार वे सही नहीं हैं। तो यह एक और चुनौती है। लेकिन अपने अध्यापन में और अधिक कौशल प्राप्त करने का एक और अवसर भी है,',\n",
       " 'टिकट की वापसी के बारे में जानकारी प्राप्त करने के लिए कृपया अपना PIN नंबर, यात्री नाम रिकार्ड डालें और अपनी टिकट नंबर जोड़ें। हम यात्री को रद्द करने की अनुमति देते हैं।',\n",
       " 'वे मेरे बारे में बात कर रहे हैं, वे क्या बौछार कर रहे हैं? तो मैंने कहा क्या आप कर रहे हैं? हम आपके फ़ैसबूक से कुछ तस्वीर ले जा रहे हैं और हम तुम्हें एक डेटिंग साइट बनाने जा रहे हैं।',\n",
       " 'चालीस डॉलर के लिए बहुत बढ़िया टीवी की तरह था और उन्होंने सचमुच दस बजे चौदहवीं सड़क पर भाग लिया, लेकिन आपको यह मिला।',\n",
       " 'आप बस देख सकते हैं, यह एक बात से ज़्यादा हो सकता है जहाँ आप घर आते हैं, आपके बच्चों की देखभाल की जाती है, जहाँ वे थे',\n",
       " 'मैं अपने बच्चों को सबसे पहले रखता हूँ, खासकर काम और दूसरी चीज़ों को रखने से पहले। तो, मेरे बच्चे हमेशा सबसे पहले आते हैं, काम से पहले, इसलिए यह हमेशा परिवार सबसे पहले होता है।',\n",
       " 'तो अपने बचपन के सबसे अच्छे दोस्त के बारे में बताओ।',\n",
       " 'क्योंकि मुझे लगता है, आपके परिवार की तरह नहीं, उनके मामले में हम में से कोई भी सचमुच इस पथ पर नहीं चलता।',\n",
       " 'क्या आपने अपने फ़्रीलेंसर के खाते में क्रेडिट कार्ड डालने के लिए क्रेडिट कार्ड रखा है?',\n",
       " 'तो आप असल में जा रहे हैं, मैं अपना खाता बंद कर रहा हूँ',\n",
       " 'खैर, और तुम्हें पता है, मुझे क्या लगता है कि अगर पुरुष इसे करने के लिए एक प्रतिस्पर्द्धा है जैसा कि उन्होंने कहा मुझे अपनी नंबर मेरी बहन से प्राप्त करने के लिए,',\n",
       " 'लेकिन मुझे पता है कि आप उनके साथ अपने रिश्ते के बारे में क्या महसूस करते हैं। यह बस ऐसा ही है जैसे आपको रिश्ता है, आपको लगता है जैसे आपका रिश्ता',\n",
       " 'आपको पता है कि आपको किसी को mentor करने की ज़रूरत है, आपको किसी से बात करने की ज़रूरत है। परिवार महत्वपूर्ण है',\n",
       " 'नीली जेन्स जाने का रास्ता था। पता चला है बहुत नहीं है। खुदरा शॉप पर आपकी क्या राय हैं',\n",
       " '(honestly take care of) मेरे बच्चों के बारे में मेरे माता-पिता जानते हैं। तो ऐसा ही उन्होंने मुझे बनाया है। अगर आप सबसे अच्छी बात के बारे में सोच सकते हैं, कैसे आप अपने माता-पिता और चीज़ों द्वारा पाल लिया गया था।',\n",
       " 'मेरे पास काम है, मैं क्या कह रहा हूँ, मैं काम पहले रखता हूँ, मुझे काम करना है',\n",
       " 'हाँ ज़ैतून में ले जा रहा हूँ तुम्हें पता है मैं क्या कह रहा हूँ',\n",
       " 'उन्होंने कभी भी हाथ नहीं बढ़ाया और कहा, अपना हाथ काटने पर तुम्हें कभी भी अफसोस नहीं होता।',\n",
       " 'आप मुझे एक दोस्त देंगे',\n",
       " 'और अपने आपको व्यक्त करने का एक तरीका यह है जैसे, आपको पता है, उदाहरण जो आपने दिए हैं इसका मतलब है कि बहुत ज़्यादा नैतिकता है।',\n",
       " 'तुम्हें पता है जैसे किसी तरह से तुम्हें पता है कि वे बैग में इसे पैकिंग करने और आकर्षित करने में सक्षम थे, वे सभी नई हैं और सिर्फ़ इसे वहाँ छोड़ दिया',\n",
       " 'फिर तुम्हारा दूसरा पसंदीदा कौन सा है',\n",
       " 'वे बहुत से कम उम्र के लोग हैं, उनकी शुरुआती बीस के दशक में, बीस के दशक के बीच में, महिला जो इस जगह चला था बहुत अच्छा था, बहुत आरामदायक. वे अपने कोड़े बंद नहीं किया, तुम्हें पता है?',\n",
       " '(ठीक है, मुझे याद है) मेरे पास एक सवाल है। क्या आप कई, समझाने के लिए सबसे अच्छा तरीका यह है कि कैसे मेरे शहर काम करता है',\n",
       " 'यकीन है, मैं भी आपकी ZIP कोड और स्ट्रीट नाम प्राप्त कर सकता हूँ, कृपया?',\n",
       " 'कोई भी आपकी पूछताछ यहाँ सिर्फ़ इस वेबसाइट के जरिए टिकट ख़रीदने से ही समर्थित की जा सकती है। ठीक है तो हम नहीं ख़रीद चुके हैं, अगर आप किसी और वेबसाइट के जरिए अपनी टिकट ख़रीदते हैं तो आपको टिकट की जाँच करनी होगी।',\n",
       " 'और आप सिर्फ़ आमतौर पर Amazon को वापस कर देते हैं?',\n",
       " 'आप लोगों और पीटर से भरे श्रोताओं की तरह अपने काम के जीवन के बारे में एक कहानी बताने जा रहे हैं',\n",
       " 'लेकिन उनकी कीमतें इतनी बढ़िया हैं, और फिर वे बहुत से चीज़ें हैं कि तुम बस की तरह की कोशिश कर रहे हैं',\n",
       " 'जैसे क्या? तुम्हारे हाथ के साथ क्या हुआ? मैं कुछ नहीं कहना चाहता था. मुझे पता भी नहीं था कि इसे कैसे कहना है और मैं कहूँगा कि मुझे काट गया',\n",
       " 'ओह भगवान, मैं विल फ़रेल से नफ़रत हूँ. तो तुम्हारा पसंदीदा फ़िल्म क्या है? विल फ़रेल के साथ फ़िल्म. मैं प्याज से नफ़रत हूँ',\n",
       " 'आपको पता है, यह लाइन बहुत लंबा हो सकता है लगता है।',\n",
       " 'ठीक है, आप सभी साफ हो गए हैं. अपने अपार्टमेंट में जाओ या उन्हें जाने देंगे. तो, तुम्हें पता है, कि हमेशा जारी रहता है. देखो, मुझे नहीं पता है कि यह कितना लंबा हो रहा है',\n",
       " 'आप बस, सिर्फ़ एक चीज़ है जो मरे जा रही है, आपका सप्ताहांत और छुट्टियाँ और ऐसी सभी चीज़ें बुक की गई हैं।',\n",
       " 'तुम्हारी माँ तुम्हें बेकार उपहार भेजती है।',\n",
       " 'नहीं अपने भाई या अपने जैसे जिसे आप अपने चचेरे भाई समझते हैं',\n",
       " 'इसका मतलब है कि आपके कंप्यूटर पर किसी वजह से पर्याप्त जगह नहीं है।',\n",
       " 'जहाँ आपको पता है कि आप धोने के लिए जाने पर अपने आपको साफ कर सकते हैं तेलों और गंधों और उन सभी चीजों के संदर्भ में, बेशक सभी की गंध बढ़िया थी, यह सिर्फ़ स्वच्छता थी और यह बहुत बढ़िया है।',\n",
       " 'हाँ वे बढ़िया हैं, तुम्हें पता है मैं क्या कह रहा हूँ?',\n",
       " 'कंप्यूटर पर एक ही तरह से हम इसे अपने दोस्तों के साथ जाँच करते हैं, अपने बच्चों या अपने बैंड के साथ काम करते हैं, तो यह जीवन का एक तथ्य है कि बहुत से लोग समाचार इस तरह मिलता है।',\n",
       " 'अपने कार के पीछे बैठते हुए और सड़क पर ध्यान देने की ज़रूरत नहीं है। साल में आप ड्राइविंग का कितना घंटा बिताते हैं विपरीत यह कैसे इस्तेमाल किया जा सकता है कि अधिक उत्पादक हो।',\n",
       " 'इसलिए वे सभी सही हैं, वे थोड़ा पागल हैं, तुम्हें पता है मैं क्या कह रहा हूँ?',\n",
       " 'मुझे नहीं पता। क्या मैं बस सचमुच बुढ़ापे में हूँ और संपर्क से बाहर है लेकिन, मुझे अजीब लगता है।',\n",
       " 'हाँ। मैं तैयार हूँ, तो शायद इसलिए मैं उस शो को देख रहा हूँ। मुझे नहीं पता, लेकिन मैं उस शो को देख रहा हूँ जो हो सकता है। आपका क्या है?',\n",
       " 'आपको पता है मैं क्या कह रहा हूँ मेरा परिवार राज्य से बाहर है',\n",
       " 'वैसे भी डाइट आपकी सबसे बड़ी समस्या है।',\n",
       " 'जब हम छोटे थे, आपका फ़ोन केस और आपका क्लिप, जो एक फ़ैशन सहायक था, और यह सच में अब नहीं है। आपका फ़ोन सिर्फ आपका फ़ोन है। लोग एक तरह से उस से आगे बढ़ गए हैं।',\n",
       " 'लेकिन उन्होंने किया और हम जा रहे थे और यह एक बहुत बढ़िया अनुभव था। मैं नहीं कहूँगा कि यह सिर्फ़ वैसा सकारात्मक और जादू करने वाला था जैसा कि आपका था क्योंकि ऐसा लगता है',\n",
       " 'मदद आगे क्या आप चाहते हैं वे सिर्फ बातचीत कौशल हैं जो हर हालात में हर किसी के साथ इस्तेमाल किया जा सकता है।',\n",
       " 'परिवार तुम्हें बहुत से छोटे तरीके से मदद करता है कि तुम भी सोचने के बारे में नहीं है। तुम तुम्हें आजादी मिल गया']"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "outputs"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
